{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8749f70-f227-4017-96f5-6a871eb84e5b",
   "metadata": {},
   "source": [
    "# A Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05073cad-908b-400c-a00f-0bc599b5de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for multi-output regression\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import *\n",
    "from keras import Input\n",
    "from keras.callbacks import CSVLogger, EarlyStopping\n",
    "\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468114f0-3a71-4fe0-a096-3d4d2fbb2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_train = pd.ExcelFile('./data/height/train.xlsx')\n",
    "xls_test = pd.ExcelFile('./data/height/test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16e0d8-408f-40fb-9c77-6fd95e44bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(data):\n",
    "    mean = data.mean(axis=0)\n",
    "    std = data.std(axis=0)\n",
    "    data = (data - mean)/std\n",
    "    \n",
    "    return data, mean, std\n",
    "\n",
    "def preprocess_data(sheet, features_all):\n",
    "    \n",
    "    sheet.columns = features_all\n",
    "    \n",
    "    # Normalize sensor readings\n",
    "    sheet['1'] = sheet['1']\n",
    "    \n",
    "    # Start from (0) position\n",
    "    sheet['x'] = sheet['x'] - sheet['x'][0]\n",
    "    \n",
    "    # Down-sampling by moving average\n",
    "    # new_data = sheet.values\n",
    "    # new_data = signal.decimate(new_data, 10, axis=0)\n",
    "    # new_data = signal.decimate(new_data, 10, axis=0)\n",
    "    # new_data = signal.decimate(new_data, 2, axis=0)\n",
    "    \n",
    "    return sheet\n",
    "\n",
    "def augment_data(data, features_all):\n",
    "    start_idx = int(data.shape[0]/2)\n",
    "    data_repeat = data[start_idx:]\n",
    "    for i in range(10):\n",
    "        data = np.concatenate((data, data_repeat), axis=0)\n",
    "    new_sheet = pd.DataFrame(data, columns = features_all)\n",
    "    preprocess_data\n",
    "    return new_sheet\n",
    "\n",
    "def load_data(xls, features_all):\n",
    "    df = pd.read_excel(xls, sheet_name=None)\n",
    "    print(\"Read {} sheets from excel file\".format(len(df)))\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    for sheet in df.values():\n",
    "        new_sheet = preprocess_data(sheet, features_all)\n",
    "        # new_sheet = augment_data(new_data, features_all)\n",
    "        new_df = pd.concat([new_df, new_sheet])\n",
    "        \n",
    "    print(\"DataFrame Shape: {} rows, {} columns\".format(*new_df.shape))\n",
    "    display(new_df.head())\n",
    "    \n",
    "    X = new_df[features_considered].values\n",
    "    y = new_df[outputs_considered].values\n",
    "    \n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "    return X, y, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3a303-5abc-4e7d-ad44-6fb60fb2e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = ['t','1','x','z','zi']\n",
    "features_considered = ['t','1','x']\n",
    "outputs_considered = features_all[-1]\n",
    "\n",
    "# load train dataset\n",
    "X_train, y_train, mean_train, std_train = load_data(xls_train, features_all)\n",
    "print('Train data loaded')\n",
    "# load test dataset\n",
    "X_test, y_test, mean_test, std_test = load_data(xls_test, features_all)\n",
    "print('Test data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa57ccf-f392-47f9-a859-014a3ec572c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use \"lr_schedule\" to see which \"learning rate\" is optimum \n",
    "# Run the model with less epoch to visualize \"learning rate\" vs \"loss\"\n",
    "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "#                     lambda epoch: 1e-8 * 10**(epoch/20))\n",
    "# Optimizer and loos parameters\n",
    "# loss = tf.keras.losses.Huber()\n",
    "# optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "# optimizer = 'adam'\n",
    "\n",
    "# get the model\n",
    "def get_model(n_inputs, n_outputs, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(n_inputs,)))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_0'))\n",
    "    model.add(Dense(8, name = 'dense_1', kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_1'))\n",
    "    # model.add(Dense(16, name = 'dense_2', kernel_initializer='he_uniform', activation='relu'))\n",
    "    # model.add(BatchNormalization(name = 'batch_norm_2'))\n",
    "    # model.add(Dense(32, name = 'dense_3', kernel_initializer='he_uniform', activation='relu'))\n",
    "    # model.add(BatchNormalization(name = 'batch_norm_3'))\n",
    "    # model.add(Dense(16, name = 'dense_4', kernel_initializer='he_uniform', activation='relu'))\n",
    "    # model.add(BatchNormalization(name = 'batch_norm_4'))\n",
    "    model.add(Dense(8, name = 'dense_5', kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_5'))\n",
    "    model.add(Dense(4, name = 'dense_6', kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_6'))\n",
    "    model.add(Dense(n_outputs, name = 'dense_7'))\n",
    "    model.compile(loss = 'mae', optimizer = optimizer, metrics = ['mae', 'mse'])\n",
    "    \n",
    "    # model = Sequential()\n",
    "    # model.add(Input(shape=(n_inputs,)))\n",
    "    # model.add(BatchNormalization(name = 'batch_norm_0'))\n",
    "    # model.add(Dense(8, name = 'dense_1', kernel_initializer='he_uniform', activation='relu'))\n",
    "    # model.add(Dropout(0.20, name = 'dropout_1'))\n",
    "    # model.add(BatchNormalization(name = 'batch_norm_1'))\n",
    "    # model.add(Dense(16, name = 'dense_2', kernel_initializer='he_uniform', activation='relu'))\n",
    "    # model.add(Dropout(0.20, name = 'dropout_2'))\n",
    "    # model.add(BatchNormalization(name = 'batch_norm_2'))\n",
    "    # model.add(Dense(8, name = 'dense_3', kernel_initializer='he_uniform', activation='relu'))\n",
    "    # model.add(Dropout(0.20, name = 'dropout_3'))\n",
    "    # model.add(BatchNormalization(name = 'batch_norm_3'))\n",
    "    # model.add(Dense(n_outputs, name = 'dense_6'))\n",
    "    # model.compile(loss = \"mse\", optimizer=optimizer, metrics = ['mae', 'mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8227dbe-776a-40c7-8f9d-00e2ccbdeb4a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# define model\n",
    "optimizer = 'adam'\n",
    "# optimizer = tf.keras.optimizers.SGD(lr=1e-3, momentum=0.8)\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "n_inputs, n_outputs = X_train.shape[1], 1\n",
    "print(n_inputs, n_outputs)\n",
    "model = get_model(n_inputs, n_outputs, optimizer)\n",
    "print(model.summary())\n",
    "\n",
    "# Train\n",
    "# print(\"\\nTRAIN MODEL...\")\n",
    "modelstart = time.time()\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=EPOCHS, verbose=1)\n",
    "# history = model.fit(train_data, epochs=EPOCHS, validation_data=test_data, verbose=1)\n",
    "\n",
    "results = list()\n",
    "rkf = RepeatedKFold(n_splits=4, n_repeats=8, random_state=1)\n",
    "for train_ix, test_ix in rkf.split(X_train):\n",
    "    ix_range = X_train.shape[0]\n",
    "    train_ix = train_ix[train_ix < ix_range]\n",
    "    test_ix = test_ix[test_ix < ix_range]\n",
    "    print(\"Filtered: TRAIN:\", train_ix.shape, \"TEST:\", test_ix.shape)\n",
    "    # prepare data\n",
    "    X_train_, X_test_ = X_train[train_ix], X_train[test_ix]\n",
    "    y_train_, y_test_ = y_train[train_ix], y_train[test_ix]\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(X_train_, y_train_, verbose=1, epochs=EPOCHS)\n",
    "    # evaluate model on test set\n",
    "    mse = model.evaluate(X_test_, y_test_, verbose=1)\n",
    "    # store result\n",
    "    # print('iteration %d: MSE = %.3f' %(len(results), mse))\n",
    "    results.append(mse)\n",
    "\n",
    "print('MSE: %.3f (%.3f)' % (mean(results), std(results))) \n",
    "\n",
    "print(\"\\nModel Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n",
    "model.save('mlp_full_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b16e47-0def-4bbc-9936-7f23f8e15a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import block_reduce\n",
    "\n",
    "def moving_average(y_pred, w):\n",
    "    f = int(w/2)\n",
    "    y_pred_max = np.zeros_like(y_pred)\n",
    "    N = y_pred.shape[0]\n",
    "    # return np.convolve(y_pred, np.ones(w), 'same') / w\n",
    "    # return block_reduce(y_pred, (w,), np.max\n",
    "    for i in range(N):\n",
    "        y_pred_max[i] = np.max(y_pred[i:i+w])\n",
    "    return y_pred_max\n",
    "\n",
    "def post_processing(y_pred):\n",
    "    y = np.absolute(y_pred)\n",
    "    normalized = (y - min(y)) / (max(y) - min(y))\n",
    "    return 4.5*normalized\n",
    "\n",
    "def plot_test_results(name, t, y_pred, y_test):\n",
    "    \n",
    "    print(\"Sheet No.\", name)\n",
    "    # y_pred_avg = moving_average(y_pred, 10)\n",
    "    \n",
    "    plt.figure(figsize=(4, 6))\n",
    "    # plt.plot(t, y_pred, 'r', label='predicted z')\n",
    "    plt.plot(t, y_pred, 'r', label='predicted z', linewidth=3)\n",
    "    plt.plot(t, y_test, 'g', label='real z',  linewidth=3)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c3393-33cc-4472-8975-78a88bf80417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Load test data\n",
    "xls_train = pd.ExcelFile('./data/height/train.xlsx')\n",
    "xls_test = pd.ExcelFile('./data/height/test.xlsx')\n",
    "df_test = pd.read_excel(xls_test, sheet_name=None)\n",
    "print(\"Read {} sheets from excel file\".format(len(df_test)))\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('./data/height/test_results.xlsx', engine='openpyxl')\n",
    "\n",
    "for name, sheet in zip(df_test.keys(), df_test.values()):\n",
    "    print(\"DataFrame Shape: {} rows, {} columns\".format(*sheet.shape))\n",
    "    new_data = preprocess_data(sheet, features_all)\n",
    "    new_sheet = pd.DataFrame(new_data, columns = features_all)\n",
    "    \n",
    "    # t = new_sheet['t']\n",
    "    x = new_sheet['x']\n",
    "    X_test = new_sheet[features_considered].values\n",
    "    # y_test = new_sheet[outputs_considered].values\n",
    "    y_test = new_sheet['z'].values\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = post_processing(y_pred)\n",
    "    y_test = np.array(y_test)\n",
    "    plot_test_results(name, x, y_pred, y_test)\n",
    "    \n",
    "    combined = np.concatenate([x[:, np.newaxis], y_test[:, np.newaxis], y_pred], axis = 1)\n",
    "    df = pd.DataFrame(combined, columns = ['x', 'real_z', 'pred_z'])\n",
    "    df.to_excel(writer, index=False, sheet_name=name)\n",
    "    \n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206a512-d487-4adc-a2d5-6ae3322c1ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
